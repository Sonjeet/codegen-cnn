{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "66e35306-44e7-48ed-8a10-99292dfbff86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33269f0f-dc92-4edd-b557-1a8fd7179ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of the mnist data:\n",
      "X_train: (60000, 28, 28)\n",
      "Y_train: (60000,)\n",
      "X_test:  (10000, 28, 28)\n",
      "Y_test:  (10000,)\n",
      "5\n",
      "0\n",
      "4\n",
      "1\n",
      "9\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "\n",
    "#printing the shapes of the vectors \n",
    "print('Shapes of the mnist data:')\n",
    "print('X_train: ' + str(train_X.shape))\n",
    "print('Y_train: ' + str(train_y.shape))\n",
    "print('X_test:  '  + str(test_X.shape))\n",
    "print('Y_test:  '  + str(test_y.shape))\n",
    "\n",
    "# TODO: will need to process the data to one-encode train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d1e8a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    # some sus syntax -> 330 + 1 + i means\n",
    "    # 3x3 grid. (+1 + i) is the position in the grid\n",
    "    # ...SUS :/\n",
    "    # it's the same as pyplot.subplot(3, 3, i+1)\n",
    "    pyplot.subplot(330 + 1 + i)\n",
    "    pyplot.imshow(train_X[i], cmap=pyplot.get_cmap('gray'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "267d8549",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    \"\"\"\n",
    "    Configurable neural net\n",
    "\n",
    "    Attributes:\n",
    "        num_layers: number of layers the net has\n",
    "        sizes: list of neurons at each layer\n",
    "        biases: list of bias vectors, where each bias vector\n",
    "            holds the biases for a given layer. input layer\n",
    "            has no bias on the neurons obvs\n",
    "        weights: list of weights matrices, where each weight\n",
    "            matrix holds the matrix of weights for a given layer.\n",
    "            matrix size is N x M where:\n",
    "            N - number of neurons at current layer (l)\n",
    "            M - number of neurons at next layer (l + 1)            \n",
    "    \"\"\"\n",
    "    def __init__(self, sizes):\n",
    "        \"\"\"\n",
    "        Construct network of layers and rand init for weights & biases\n",
    "\n",
    "        Args:\n",
    "            sizes: list holds the number of neurons\n",
    "                at each layer\n",
    "       \"\"\"\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(b, 1) for b in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x)\n",
    "                        for (x,y) in zip(sizes[:-1], sizes[1:])]\n",
    "\n",
    "    def metadata(self):\n",
    "        \"\"\"\n",
    "        Prints the metadata of this class\n",
    "        \"\"\"\n",
    "        print('=============\\nNetwork metadata:')\n",
    "        print('=============')\n",
    "        print(f'Layers: {self.num_layers}')\n",
    "        print(f'Sizes: {self.sizes}')\n",
    "        \n",
    "        print(f'Biases: {[np.asarray(b).shape for b in self.biases]}')\n",
    "        print(f'Weights: {[np.asarray(w).shape for w in self.weights]}')\n",
    "\n",
    "    def feedforward(self, a):\n",
    "        \"\"\"\n",
    "        Does a forward propagation and computes the activations in\n",
    "        the output layer of the network\n",
    "\n",
    "        Args:\n",
    "            a: the activations from the previous layer, if first\n",
    "            hidden layer then a is just the input to the network\n",
    "        \"\"\"\n",
    "        for (w, b) in zip(self.weights, self.biases):\n",
    "            a = sigmoid(np.dot(w, a) + b)\n",
    "        return a\n",
    "\n",
    "    def SGD(self,\n",
    "            training_data, \n",
    "            epochs,\n",
    "            mini_batch_size,\n",
    "            lr,\n",
    "            test_data = None):\n",
    "        \"\"\"\n",
    "        stoch grad desc\n",
    "        for each epoch, for each mini batch in a batch:\n",
    "        we wanna compute the following for each mini batch:\n",
    "        dc/dw, dc/db, error for the output and hidden layers\n",
    "        if using minibatches we'll just accumulate gradients\n",
    "        throughout the epoch, i think at the end we can just\n",
    "        perform an avg of the gradient accum / num of mini batches\n",
    "        need to use extra storage for this\n",
    "        mini batch should be shuffled too for each epoch\n",
    "\n",
    "        Compute the stochastic gradient descent\n",
    "\n",
    "        Args:\n",
    "            training_data: list of tuples holding [(x1,y1), ..., (xN,yN)]\n",
    "                where x is a vector of input features e.g. pixels of img\n",
    "                where y is a vector of one-hot encoded 10 classification labels\n",
    "            epochs: number of epochs during training\n",
    "            mini_batch_size: number of training examples in a given mini batch\n",
    "            lr: float for the learning rate\n",
    "            test_data: optional, will be list of tuples, same as training_data\n",
    "        \"\"\"\n",
    "        for epoch in range(epochs):\n",
    "            random.shuffle(training_data)\n",
    "            mini_batches = [\n",
    "                training_data[k:k + mini_batch_size]\n",
    "                for k in range(0, len(training_data), mini_batch_size)\n",
    "            ]\n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(mini_batch, lr);\n",
    "\n",
    "            if test_data:\n",
    "                print(f'Epoch {epoch}: {self.evaluate(test_data)} / {len(test_data)} : {self.evaluate(test_data) * 100 / len(test_data)}%')\n",
    "            else:\n",
    "                print(f'Epoch {epoch} complete')  \n",
    "\n",
    "    def update_mini_batch(self, mini_batch, lr):\n",
    "        \"\"\"\n",
    "        for a given mini batch which should have x,y where:\n",
    "        x - training data\n",
    "        y - label\n",
    "        compute the grad of w,b then accumulate this until\n",
    "        the entire batch has been processed\n",
    "        after the entire backwards pass just update the weights\n",
    "        and biases with the avg'd accumulated grads\n",
    "        \"\"\"\n",
    "        grad_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        grad_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        for (x, y) in mini_batch:\n",
    "            delta_w, delta_b = self.backprop(x, y)\n",
    "            grad_w = [grads + deltas for grads, deltas in zip(grad_w, delta_w)]\n",
    "            grad_b = [grads + deltas for grads, deltas in zip(grad_b, delta_b)]\n",
    "        \n",
    "        self.weights = [weights - ((lr * grads) / len(mini_batch))\n",
    "                        for weights, grads in zip(self.weights, grad_w)]\n",
    "        self.biases = [biases - ((lr * grads) / len(mini_batch))\n",
    "                       for biases, grads in zip(self.biases, grad_b)]\n",
    "\n",
    "    def backprop(self, x, y):\n",
    "        \"\"\"\n",
    "        do the backwards pass, init za zero'd bias and weights matrix\n",
    "        compute output delta\n",
    "        compute delta at each layer\n",
    "        return the biases and weights grads for each network layer\n",
    "        \"\"\"\n",
    "        grad_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        grad_b = [np.zeros(b.shape) for b in self.biases]\n",
    "\n",
    "        # keep a ref to activations and weighted inputs because\n",
    "        # layers need other layers' as, zs\n",
    "        activation = x\n",
    "        activations = [x]\n",
    "        zs = []\n",
    "        \n",
    "        # compute activations for the network\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            z = np.dot(w, activation) + b\n",
    "            zs.append(z)\n",
    "            activation = sigmoid(z)\n",
    "            activations.append(activation)\n",
    "        \n",
    "        delta = self.cost_derivative(activations[-1], y) * sigmoid_derivative(zs[-1])\n",
    "        grad_b[-1] = delta\n",
    "        grad_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "\n",
    "        for l in range(2, self.num_layers):\n",
    "            z = zs[-l]\n",
    "            a_primed = sigmoid_derivative(z)\n",
    "            delta = np.dot(self.weights[-l+1].transpose(), delta) * a_primed\n",
    "            grad_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "            grad_b[-l] = delta\n",
    "\n",
    "        return (grad_w, grad_b)\n",
    "    \n",
    "    def evaluate(self, test_data):\n",
    "        test_results = [(np.argmax(self.feedforward(x)), y)\n",
    "                        for (x, y) in test_data]\n",
    "        return sum(int(x == y) for (x, y) in test_results)\n",
    "\n",
    "\n",
    "    def cost_derivative(self, output_activations, y):\n",
    "        \"\"\"\n",
    "        for now probs just the MSE\n",
    "        deriv of MSE implemented (simple)\n",
    "        \"\"\"\n",
    "        return output_activations - y\n",
    "\n",
    "# Misc functions - probs can be part of a utils/math/linalg lib\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    impl sigmoid activation algo\n",
    "    \"\"\"\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    \"\"\"\n",
    "    impl sigmoid derivative\n",
    "    \"\"\"\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6f7334ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes validation:\n",
      "==================================================\n",
      "Training set size: 60000\n",
      "Test set size: 10000\n",
      "\n",
      "Training data format:\n",
      "  Input (x) shape: (784, 1) (expected: (784, 1))\n",
      "  Label (y) shape: (10, 1) (expected: (10, 1))\n",
      "  Label (y) sample:\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
      "\n",
      "Test data format:\n",
      "  Input (x) shape: (784, 1) (expected: (784, 1))\n",
      "  Label (y) type: <class 'numpy.uint8'> (expected: int)\n",
      "  Label (y) value: 7\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "def vectorized_result(j):\n",
    "    \"\"\"Convert digit (0-9) to one-hot encoded column vector\"\"\"\n",
    "    e = np.zeros((10, 1))\n",
    "    e[j] = 1.0\n",
    "    return e\n",
    "\n",
    "def load_data_wrapper():\n",
    "    \"\"\"\n",
    "    Load MNIST data from Keras and format for Network class.\n",
    "\n",
    "    Returns:\n",
    "        training_data: list of (x, y) tuples where:\n",
    "            x: (784, 1) column vector of pixel values\n",
    "            y: (10, 1) one-hot encoded column vector\n",
    "        test_data: list of (x, y) tuples where:\n",
    "            x: (784, 1) column vector of pixel values\n",
    "            y: integer label (0-9)\n",
    "    \"\"\"\n",
    "    (train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "\n",
    "    # Training data: reshape images to (784,1) and one-hot encode labels\n",
    "    training_inputs = [np.reshape(x, (784, 1)) / 255.0 for x in train_X]\n",
    "    training_results = [vectorized_result(y) for y in train_y]\n",
    "    training_data = list(zip(training_inputs, training_results))\n",
    "\n",
    "    # Test data: reshape images to (784,1), keep labels as integers\n",
    "    test_inputs = [np.reshape(x, (784, 1)) / 255.0 for x in test_X]\n",
    "    test_data = list(zip(test_inputs, test_y))\n",
    "\n",
    "    return (training_data, test_data)\n",
    "\n",
    "# Load and validate data\n",
    "training_data, test_data = load_data_wrapper()\n",
    "\n",
    "print(\"Data shapes validation:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Training set size: {len(training_data)}\")\n",
    "print(f\"Test set size: {len(test_data)}\")\n",
    "print()\n",
    "\n",
    "# Check first training example\n",
    "x_train, y_train = training_data[0]\n",
    "print(\"Training data format:\")\n",
    "print(f\"  Input (x) shape: {x_train.shape} (expected: (784, 1))\")\n",
    "print(f\"  Label (y) shape: {y_train.shape} (expected: (10, 1))\")\n",
    "print(f\"  Label (y) sample:\\n{y_train.T}\")\n",
    "print()\n",
    "\n",
    "# Check first test example\n",
    "x_test, y_test = test_data[0]\n",
    "print(\"Test data format:\")\n",
    "print(f\"  Input (x) shape: {x_test.shape} (expected: (784, 1))\")\n",
    "print(f\"  Label (y) type: {type(y_test)} (expected: int)\")\n",
    "print(f\"  Label (y) value: {y_test}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b7ca8850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0.9152\n",
      "Epoch 1: 0.925\n",
      "Epoch 2: 0.9323\n",
      "Epoch 3: 0.939\n",
      "Epoch 4: 0.9422\n",
      "Epoch 5: 0.946\n",
      "Epoch 6: 0.9456\n",
      "Epoch 7: 0.9495\n",
      "Epoch 8: 0.9485\n",
      "Epoch 9: 0.9478\n",
      "Epoch 10: 0.948\n",
      "Epoch 11: 0.9496\n",
      "Epoch 12: 0.9512\n",
      "Epoch 13: 0.9525\n",
      "Epoch 14: 0.9513\n",
      "Epoch 15: 0.9548\n",
      "Epoch 16: 0.9529\n",
      "Epoch 17: 0.9535\n",
      "Epoch 18: 0.9539\n",
      "Epoch 19: 0.9515\n",
      "Epoch 20: 0.9546\n",
      "Epoch 21: 0.9534\n",
      "Epoch 22: 0.9536\n",
      "Epoch 23: 0.9529\n",
      "Epoch 24: 0.9548\n"
     ]
    }
   ],
   "source": [
    "training_data, test_data = load_data_wrapper()\n",
    "\n",
    "net = Network([784, 30, 10])\n",
    "net.SGD(training_data,\n",
    "        epochs=25,\n",
    "        mini_batch_size=10,\n",
    "        lr=3.0,\n",
    "        test_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2116d668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 8381 / 10000 : 83.81%\n",
      "Epoch 1: 9262 / 10000 : 92.62%\n",
      "Epoch 2: 9376 / 10000 : 93.76%\n",
      "Epoch 3: 9398 / 10000 : 93.98%\n",
      "Epoch 4: 9420 / 10000 : 94.2%\n",
      "Epoch 5: 9430 / 10000 : 94.3%\n",
      "Epoch 6: 9448 / 10000 : 94.48%\n",
      "Epoch 7: 9465 / 10000 : 94.65%\n",
      "Epoch 8: 9487 / 10000 : 94.87%\n",
      "Epoch 9: 9495 / 10000 : 94.95%\n",
      "Epoch 10: 9517 / 10000 : 95.17%\n",
      "Epoch 11: 9495 / 10000 : 94.95%\n",
      "Epoch 12: 9510 / 10000 : 95.1%\n",
      "Epoch 13: 9502 / 10000 : 95.02%\n",
      "Epoch 14: 9545 / 10000 : 95.45%\n",
      "Epoch 15: 9495 / 10000 : 94.95%\n",
      "Epoch 16: 9535 / 10000 : 95.35%\n",
      "Epoch 17: 9525 / 10000 : 95.25%\n",
      "Epoch 18: 9487 / 10000 : 94.87%\n",
      "Epoch 19: 9543 / 10000 : 95.43%\n",
      "Epoch 20: 9530 / 10000 : 95.3%\n",
      "Epoch 21: 9556 / 10000 : 95.56%\n",
      "Epoch 22: 9530 / 10000 : 95.3%\n",
      "Epoch 23: 9526 / 10000 : 95.26%\n",
      "Epoch 24: 9536 / 10000 : 95.36%\n"
     ]
    }
   ],
   "source": [
    "training_data, test_data = load_data_wrapper()\n",
    "\n",
    "net = Network([784, 30, 10])\n",
    "net.SGD(training_data,\n",
    "        epochs=25,\n",
    "        mini_batch_size=10,\n",
    "        lr=3.0,\n",
    "        test_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dd8ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
